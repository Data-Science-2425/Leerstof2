{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3680c555",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Tot nu toe is de code voor het opbouwen van een model vespreid over twee stappen. \n",
    "Een preprocesing stap waar alle transformaties op gebeuren op de data bruikbaar te maken zoals schaling, invullen van ontbrekende waarden, hogere orde features, ...\n",
    "In een latere stap gebeurd dan het trainen van een model.\n",
    "Echter is het zo dat als je het model in gebruik wilt nemen in een applicatie dat je ook exact dezelfde preprocessing stappen nodig hebt omdat je de data die je aan het model presenteert hetzelfde moet zijn.\n",
    "Om deze reden is de vorige aanpak niet praktisch aangezien het eenvoudig is om een fout te maken.\n",
    "Het is ook geen onderhoudbare oplossing omdat het veel manueel werk vereist indien er een bepaalde stap aangepakt wordt.\n",
    "\n",
    "Om dit tegen te gaan kan men gebruik maken van Pipelines. \n",
    "Hiermee definieer je de flow die de data moet ondergaan om verwerkt te worden. \n",
    "De volledige pipeline of flow kan dan gebruikt worden om te trainen en te gebruiken in productie. \n",
    "Hierdoor worden de preprocessing stappen (zoals scalers, ordinal of one-hotencoder) steeds enkel op de training folds uitgevoerd.\n",
    "Een bijkomende voordeel is dat ook parameters van de preprocessing stappen meegenomen kunnen worden in de gridsearch.\n",
    "\n",
    "Let op dat NaN waarden invullen kan gebeuren in de pipeline maar rijen weglaten kan niet gedaan worden tijdens de pipeline. Echter is het gebruik van een pipeline een goede stap in het verhogen van de leesbaarheid van een code stuk en wordt het daardoor veelvuldig gebruikt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66da894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97af998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2d1af1d",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "Maak een pipeline voor een gridsearch uit te voeren op de diabetes-dataset in sklearn. Gebruik een Min-Max scaler voor de numerieke waarden en een ordinal encoder voor de categorieke kolommen.\n",
    "Zoek naar de beste combinatie van hyperparameters van een SVM-classifier door middel van een grid search met cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66e916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
