{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8266688",
   "metadata": {},
   "source": [
    "# Classificatie - Logistic Regression\n",
    "\n",
    "## Wat is classificatie?\n",
    "\n",
    "Bij regressie wordt er getracht een manier te zoeken om op basis van een aantal inputs/features een continue waarde te voorspellen.\n",
    "Bij classificatie omvat machine learning technieken waar een model getrained wordt dat op basis van de input bepaalt in welke categorieen je input thuishoort.\n",
    "Een model dat een categorie toekent aan een bepaalde set input-data kan ook een **classifier** genoemd worden.\n",
    "Het classificatieprobleem hoort nog steeds thuis onder **supervised learning** omdat er nog steeds gebruikt gemaakt wordt van een output/label/target om het model te trainen.\n",
    "\n",
    "Enkele voorbeelden van classificatieproblemen zijn\n",
    "* Spam detectie\n",
    "* Medische diagnoses\n",
    "* Kwaliteitscontrole\n",
    "* Geschreven tekst inlezen\n",
    "* ...\n",
    "\n",
    "\n",
    "## Types van classifiers\n",
    "\n",
    "Op basis van hoe de data gelabeled wordt kunnen we drie types van classifiers onderscheiden:\n",
    "* Binaire classifier: Er zijn twee verschillende klasses (goedgekeurd of niet, kwaadaardig vs goedaardig, ...). Lijkt simplistisch maar komt heel veel voor.\n",
    "* Multiclass classifier: Er zijn een willekeurig aantal klassen en er kan er maar 1 toegekend worden. Een voorbeeld hiervan is gezichtsherkenning (elk gezicht kan maar bij 1 persoon horen).\n",
    "* Multilabel classifier: Er zijn een willekeurig aantal klassen en 1 input kan tot meerdere klassen behoren, bijvoorbeeld op een foto kan je meerdere zaken herkennen zoals een boom, wolken, gras, struiken, dieren, ...\n",
    "\n",
    "## Kan hier ook lineaire regressie gebruikt worden?\n",
    "\n",
    "Een eerste mogelijkheid om classificatie uit te voeren is om elke klasse een apart getal te geven en dan lineaire regressie uit te voeren.\n",
    "Hierdoor bekomen we een getal en dan kunnen we kijken naar welk cijfer/klasse er het dichts bij licht.\n",
    "De problemen met deze aanpak kunnen het makkelijkst worden toegelicht doorm iddel van een voorbeeld.\n",
    "Doorheen deze notebook gaat er grotendeels gewerkt worden met [deze dataset](https://www.kaggle.com/elakiricoder/gender-classification-dataset) die 7 zaken gemeten heeft in het gezicht van zowel mannen als vrouwen.\n",
    "Deze dataset gaan we gebruiken om op basis van deze metingen te gaan bepalen of de bijhorende persoon een vrouw of man is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac429f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import opendatasets as od\n",
    "\n",
    "# sklearn\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7372ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(\"https://www.kaggle.com/joshmcadams/oranges-vs-grapefruit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb04d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".\\\\oranges-vs-grapefruit\\\\citrus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc76994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"output\"] = df.name == \"orange\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc0693",
   "metadata": {},
   "source": [
    "Waneer we nu een scatterplot tekenen van een kleine datasample en lineaire regressie zouden laten uitvoeren bekomen we onderstaand resultaat.\n",
    "Voor classificatie zouden we beslissen dat wanneer het minder is dan de helft, dat het dan een orange is en anders pompelmoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913584cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(group):\n",
    "    s = group.sort_values(\"weight\")\n",
    "    if group.name == \"orange\":\n",
    "        return s.head()\n",
    "    return s.tail()\n",
    "df_trimmed = df.groupby([\"name\"]).apply(split)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(pd.DataFrame(df_trimmed.diameter), df_trimmed.output)\n",
    "x_test = [4, 16]\n",
    "y_test = model.predict(pd.DataFrame(x_test))\n",
    "\n",
    "sns.scatterplot(x = 'diameter', y ='output', data=df_trimmed, hue='output')\n",
    "plt.plot(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17820979",
   "metadata": {},
   "source": [
    "Met deze plot zou je kunnen denken dat lineaire regressie kan gebruikt worden.\n",
    "Daarom hebben we eens een andere groep ook geplot en daar zie je dat er toch een aantal problemen zijn met lineaire regressie te gebruiken voor classificatie.\n",
    "* Outliers hebben een grote impact op de trendlijn en dus op de manier dat de classificatie gebeurd\n",
    "* Als de ene klas 0 is en de andere 1, dan kunnen we waarden voorspellen die kleiner zijn dan 0 en groter dan 1. Dit komt niet overeen met kansen dus is het lastiger om te interpreteren. \n",
    "* Als de klassen niet gebalanceerd zijn kan het zijn dat er een grotere bias is voor de ene klassen. Dit wordt ook hieronder. aangetoond.\n",
    "\n",
    "De combinatie van deze problemen zorgt ervoor dat lineaire regressie zelden een goede oplossing is voor classificatieproblemen.\n",
    "Gelukkig bevat het domein van classificatie een hele hoop machine learning technieken die beter bestand zijn tegen deze problemen.\n",
    "In de loop van de cursus gaan we er een aantal van bestuderen, namelijk:\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* Naive Bayes\n",
    "* Decision Trees\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b595b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_outlier(group):\n",
    "    s = group.sort_values(\"weight\")\n",
    "    if group.name == \"orange\":\n",
    "        return s.head()\n",
    "    return pd.concat([s.tail(1), s[-1000:-995]])\n",
    "df_trimmed = df.groupby([\"name\"]).apply(split_outlier)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(pd.DataFrame(df_trimmed.diameter), df_trimmed.output)\n",
    "x_test = [4, 16]\n",
    "y_test = model.predict(pd.DataFrame(x_test))\n",
    "\n",
    "sns.scatterplot(x = 'diameter', y ='output', data=df_trimmed, hue='output')\n",
    "plt.plot(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac877895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_inbalanced(group):\n",
    "    s = group.sort_values(\"weight\")\n",
    "    if group.name == \"orange\":\n",
    "        return s.head()\n",
    "    return s.tail(2000)\n",
    "df_trimmed = df.groupby([\"name\"]).apply(split_inbalanced)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(pd.DataFrame(df_trimmed.diameter), df_trimmed.output)\n",
    "x_test = [4, 16]\n",
    "y_test = model.predict(pd.DataFrame(x_test))\n",
    "\n",
    "sns.scatterplot(x = 'diameter', y ='output', data=df_trimmed, hue='output')\n",
    "plt.plot(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9f7f9-d267-49b9-b2aa-d46c590ee1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_inbalanced(group):\n",
    "    s = group.sort_values(\"weight\")\n",
    "    if group.name == \"orange\":\n",
    "        return s.head()\n",
    "    return s.tail(2000)\n",
    "df_trimmed = df.groupby([\"name\"]).apply(split_inbalanced)\n",
    "\n",
    "model = LogisticRegression(penalty=None)\n",
    "model.fit(pd.DataFrame(df_trimmed.diameter), df_trimmed.output)\n",
    "x_test = np.linspace(4,16,1000)\n",
    "y_test = model.predict(pd.DataFrame(x_test))\n",
    "\n",
    "sns.scatterplot(x = 'diameter', y ='output', data=df_trimmed, hue='output')\n",
    "plt.plot(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f73b227",
   "metadata": {},
   "source": [
    "## Evaluatie van classificatie\n",
    "\n",
    "In tegenstelling tot lineaire regressie kunnen we niet de afstand tot de gewenste output gebruiken om verschillende classifiers te gaan evalueren.\n",
    "Een mogelijkheid die kan werken is om te kijken naar het percentage van inputs die correct geklassificieerd zijn.\n",
    "Dit wordt ook de accuraatheid of accuracy genoemd.\n",
    "Enkel deze metriek gebruiken heeft echter problemen bij het classificieren van zeldzame events of niet-gebalanceerde data.\n",
    "Een classifier zou bijvoorbeeld voor iets dat in maar 1 van de 1000 gevallen voorkomt kunnen voorspellen dat het nooit voorkomt maar toch een accuraatheid bekomen van 99,9%.\n",
    "\n",
    "Om dit op te vangen kan de zogenoemde [confusionmatrix](https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826) bepaald worden.\n",
    "Hierin wordt bijgehouden voor elke klasse hoeveel voorspellingen er correct waren en hoeveel niet.\n",
    "Op basis van deze matrix kunnen de volgende metrieken berekend worden:\n",
    "* Accuraatheid: algemene correctheid $\\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "* Precisie: Accuraatheid binnen positieve voorspellingen $\\frac{TP}{TP+FP}$\n",
    "* Specificiteit: Accuraatheid binnen negatieve samples $\\frac{TN}{TN+FP}$\n",
    "* Recall: Accuraatheid binnen positieve samples $\\frac{TP}{TP+FN}$\n",
    "* F1-score: Combinatie Precisie en Recall: $2\\frac{Precisie*Recall}{Precisie+Recall} = \\frac{2TP}{2TP+FP+FN}$\n",
    "\n",
    "De [.score](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score) functie van het LogisticRegression model berekent de accuraatheid van het model maar de andere metrieken kunnen een veel nauwkeuriger beeld geven over de correcte werken van het model.\n",
    "\n",
    "![matrix](images/confusionMatrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c8209e",
   "metadata": {},
   "source": [
    "## Multi-class classification\n",
    "\n",
    "In het bovenstaande voorbeeld zijn de training examples onderverdeeld in twee klassen.\n",
    "In de praktijk komt het ook vaak voor dat er meerdere klasses mogelijk zijn, zoals meerdere types fruit, meerdere soorten hondenrassen, ...\n",
    "Om dit aan te pakken zijn er twee veelgebruikte technieken: One vs All en One vs One.\n",
    "Meer informatie over hoe de LogisticRegression van sklearn kan gebruikt worden voor multi-class problemen op te lossen vind je [hier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "Dan gaat het specifiek om het multi-class probleem.\n",
    "\n",
    "### One vs All\n",
    "\n",
    "Bij deze techniek maak 1 classifier per klasse die je hebt.\n",
    "Deze classifier bepaalt of een input van die bepaalde klasse is of niet.\n",
    "Met deze techniek worden er dus N classifiers getrained.\n",
    "Het voordeel hiervan is dat er minder classifiers nodig zijn dan in de One-Vs-One-techniek waardoor het sneller te trainen is.\n",
    "Het nadeel echter is dat de techniek gevoeliger is aan niet-gebalanceerde data.\n",
    "Deze techniek wordt ook vaak One-Vs-The-Rest genoemd.\n",
    "\n",
    "Een opmerking bij techniek is dat het mogelijk is dat twee of meerdere classifiers aangeven dat een input tot die klasse hoort.\n",
    "In het geval dat er een dergelijk conflict opduikt wordt de klasse die de hoogste kans aangeeft gekozen. \n",
    "\n",
    "![onevsall](images/oneVsAll.png)\n",
    "\n",
    "### One vs One\n",
    "\n",
    "Bij deze techniek maken we een classifier aan voor elke combinatie van 2 klassen aan. \n",
    "Hierdoor zijn er $\\frac{N(N-1)}{2}$ classifiers nodig wat snel kan oplopen in vergelijking met de voorgaande techniek.\n",
    "Op basis van onderstaand voorbeeld werkt deze techniek als volgt:\n",
    "* Eerst wordt er gekeken of de input van de rode of de blauwe klasse is. \n",
    "* Indien het niet van de rode is, wordt er nog gekeken of het blauw of groen is.\n",
    "* Indien het niet de blauwe klasse is, wordt er nog gekeken of het rood of groen is.\n",
    "\n",
    "Hoewel deze methode een grotere trainingstijd nodig heeft door het toegenomen aantal classifiers zijn er wel een aantal voorbeelden:\n",
    "* Minder gevoelig voor niet gebalanceerde data\n",
    "* Geen wazige gebieden waar meerdere classifiers kunnen voorspellen dat het van die klasse is.\n",
    "\n",
    "![onevsall](images/oneVsOne.png)\n",
    "\n",
    "### Multinomial\n",
    "\n",
    "Sommige van de solvers in logistic regression maken het ook mogelijk om rechtstreeks te werken met meerdere klassen. In deze gevallen kan het \"multi-class\" argument op \"multinomial\" gezet worden. Dit is het standaard gedrag tenzij de solver op \"liblinear\" staat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneVsOneClassifier()\n",
    "OneVsRestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ea287",
   "metadata": {},
   "source": [
    "### Multiclass evaluatie\n",
    "\n",
    "De confusion matrix in het geval van meerdere klassen kan uitgebreid worden naar onderstaand voorbeeld voor drie klassen. \n",
    "\n",
    "![matrix](images/confusionMatrixMulti.png)\n",
    "\n",
    "Hier is het niet rechtstreeks zichtbaar wat de True Positive, True Negative, ... waarden zijn.\n",
    "We kunnen deze echter eenvoudig berekenen per klasse. \n",
    "Dan kunnen we de besproken metrieken ook per klasse berekenen zodat we onderstaande resultaten bekomen.\n",
    "\n",
    "![matrix](images/metriekenMulti.png)\n",
    "\n",
    "Met behulp van deze matrix kunnen verschillende modellen vergeleken worden.\n",
    "Echter kan er nog iets verder gegaan worden in het combineren van waarden door een globale F1-score te bepalen.\n",
    "Hier zijn meerdere opties voor, namelijk:\n",
    "* Micro F1: Globale F1 op basis van total TP, FN en FP. Merk op dat door geen onderscheid te maken tussen klassen dat $Micro F1 = Precisie = Recall = Accuraatheid$\n",
    "* Macro F1: (Niet gewogen) Gemiddelde van alle F1-scores per klasse.\n",
    "* Weighted F1: Gewogen gemiddelde van de F1-scores per klasse (gewichten = aantal samples van die klasse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82563120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7fd150",
   "metadata": {},
   "source": [
    "## Voorbeeld\n",
    "\n",
    "Gebruik nu [deze dataset](https://www.kaggle.com/c/titanic/overview) om onderstaande vragen op te lossen:\n",
    "* Maak een model om op basis van de kolommen te voorspellen of een bepaalde passagier de tocht op de titanic zou overleven\n",
    "* Bereken voor dit model de accuraatheid, recall, precisie en F1-score. \n",
    "* Probeer hogere-orde features te gebruiken om deze waarden te verhogen\n",
    "* Maak een scatter plot voor de leeftijd vs hoeveel er betaald was voor het ticket. Geef ook aan welke datapunten de ramp overleefd hebben en welke niet.\n",
    "* Maak nu een one-vs-all en one-vs-one classifier aan om de klasse van een persoon te voorspellen op basis van de andere gegevens. Gebruik hiervoor niet de testset omdat hier geen data voor beschikbaar is in de testset maar splits je trainingsset op in twee delen.\n",
    "* Schrijf nu een functie om de confusion matrix en de metrieken per klasse en de gecombineerde F1-scores te bepalen. Zoek naar het beste model.\n",
    "* Welke hyperparameters heb je gebruikt tijdens het zoeken naar het model? Hoeveel parameters heeft je uiteindelijke model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff707ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(\"https://www.kaggle.com/c/titanic/overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75de16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc36598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77580af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04f399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44043b59-623d-4b36-bb19-12ec05548f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf5f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ed94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
