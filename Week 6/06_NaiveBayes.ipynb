{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea0993c",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "De Naive Bayes techniek is een **supervised** machine learning techniek voor **classificatie** problemen op te lossen.\n",
    "Dit is een redelijke oude techniek en wordt tegenwoordig al iets minder gebruikt.\n",
    "Echter is het een zeer snelle techniek, zelfs als er heel veel features zijn.\n",
    "Hierdoor is deze techniek wel nog nuttig in real-time toepassingen.\n",
    "\n",
    "Het verschil met de SVM of logistische regressie classifiers is dat dit een **Generative classifier** is in plaats van een Discriminatieve classifier.\n",
    "Een discriminatieve classifier is een classifier die de grens leer tussen twee verschillende klassen.\n",
    "Dit wil zeggen dat er een scheidingslijn gezocht wordt die geoptimaliseerd wordt op basis van misclassificaties.\n",
    "Bij discriminative wordt er dus vooral gekeken naar wat de klassen verschillend maakt.\n",
    "Een generative classifier echter gaat vooral kijken naar wat observaties van dezelfde klassen gemeenschappelijk hebben (welke features maken een observatie tot die klasse)\n",
    "Hierbij worden de verschillende features bekeken en er wordt gezocht naar een algemene verdeling van de observaties die tot elke klasse hoort. \n",
    "\n",
    "De benaming komt voort uit het feit dat Naive Bayes gebruikt maakt van de Bayes regel over conditionele probabiliteiten waarbij gebruik gemaakt wordt van de naieve veronderstelling dat de features onafhankelijk zijn van elkaar.\n",
    "\n",
    "## Werking: Bayes rule\n",
    "\n",
    "**Voorbeeld:**\n",
    "\n",
    "Kans dat je kanker hebt $1\\%$ ($P(Kanker) = 1\\% = 0.01$)\n",
    "\n",
    "Stel dat er een test is om kanker op te sporen die:\n",
    "* In 90% van de gevallen is de test positief als je kanker hebt (sensitiviteit)\n",
    "* In 90% van de gevallen is de test negatief als je geen kanker hebt (specificiteit)\n",
    "\n",
    "Wat is nu de kans dat je kanker hebt als deze test positief blijkt te zijn?\n",
    "\n",
    "Deze kans is niet 90% omdat er ook rekening gehouden moet worden met de kans dat iemand kanker heeft.\n",
    "We zijn dus echter op zoek naar $P(\\text{Kanker}|\\text{Positief})$.\n",
    "Door gebruik te maken van de Bayes regel kan dit uitgeschreven worden als volgt:\n",
    "\n",
    "$P(\\text{Kanker}|\\text{Positief}) = \\frac{P(\\text{Positief}|\\text{Kanker})P(\\text{Kanker})}{P(\\text{Positief})}$\n",
    "\n",
    "$P(\\text{Kanker}|\\text{Positief}) = \\frac{0.9 * 0.01}{0.01 * 0.9 + 0.1*0.99} = 0.08333$\n",
    "\n",
    "De verschillende kansen in deze uitdrukking hebben de volgende definities:\n",
    "* Prior: $P(\\text{Kanker})$: Kans dat iemand kanker heeft (zonder te testen)\n",
    "* Likelihood: $P(\\text{Positief}|\\text{Kanker})$: De kans dat je positief test als je kanker hebt\n",
    "* Marginal: $P(\\text{Positief})$: De kans dat je positief test\n",
    "* Posterior: $P(\\text{Kanker}|\\text{Positief})$: De kans dat je kanker hebt als je positief test\n",
    "\n",
    "De algemene vorm van bovenstaande berekening kan geschreven worden als\n",
    "\n",
    "$P(\\text{H}|\\text{e}) = \\frac{P(\\text{e}|\\text{H})P(\\text{H})}{P(\\text{e})}$\n",
    "\n",
    "waar: \n",
    "* e de evidence voorstelt (de features)\n",
    "* H de hypothese voorstelt (de features horen bij klasse $i$)\n",
    "\n",
    "Dit type classifier kan geimplementeerd worden door gebruik te maken van de [GaussianNB klasse](https://scikit-learn.org/stable/modules/naive_bayes.html) uit sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c98207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e844be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "wine = datasets.load_wine()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2)\n",
    "\n",
    "naiveBayes = GaussianNB()\n",
    "naiveBayes.fit(X_train, y_train)\n",
    "y_pred = naiveBayes.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f258ea8",
   "metadata": {},
   "source": [
    "# Tekstclassificatie\n",
    "\n",
    "Een veel voorkomende toepassing bij machine learning is het werken op tekstfragmenten.\n",
    "Denk bijvoorbeeld aan chatbots, spam-mail detectie, automatische call-centers, ...\n",
    "Dit wordt ook NLP of Natural Language Processing genoemd.\n",
    "De moeilijkheid bij het werken met NLP is dat de betekenis van een woord vaak sterk afhankelijk is van de context van het stuk tekst.\n",
    "Om met deze complexiteit om te gaan zijn geavanceerde machine learning technieken nodig zoals deep learning.\n",
    "Dit komt later bij Machine Learning in meer detail aan bod.\n",
    "De complexiteit kan echter sterk gereduceerd worden door te veronderstellen dat alle woorden in het tekstfragment onafhankelijk zijn van elkaar.\n",
    "In de rest van deze notebook wordt gewerkt met het typische voorbeeld over spam-detectie op inkomende mails.\n",
    "\n",
    "## Typisch voorbeeld: Spam detectie\n",
    "\n",
    "Hieronder staat een typisch voorbeeld van een spam mail.\n",
    "\n",
    "![spam-example](images\\spam1.jpg)\n",
    "\n",
    "Het doel is nu om deze mail te classificeren als spam of not spam (dit laatste wordt ook \"ham\" genoemd).\n",
    "We zoeken dus de kans dat deze tekst spam is op basis van alle woorden die erin staat.\n",
    "Hierdoor bekomen we de volgende vergelijking.\n",
    "\n",
    "$P(\\text{Spam}|w_1,w_2, \\dots w_n) = \\frac{P(w_1,w_2, \\dots w_n|\\text{Spam}) P(\\text{Spam})}{P(w_1,w_2, \\dots w_n)}$\n",
    "\n",
    "Na toepassing van de Bayes rule kunnen we dit ook schrijven als:\n",
    "\n",
    "$P(\\text{Spam}|w_1,w_2, \\dots w_n) = \\frac{P(w_1|w_2, \\dots w_n,\\text{Spam})P(w_2|w_3, \\dots w_n,\\text{Spam})\\dots P(\\text{Spam})}{P(w_1,w_2, \\dots w_n)}$\n",
    "\n",
    "De kansen in de teller van de breuk geven de kansen weer om een bepaald woord te vinden op basis van de andere woorden in de tekst.\n",
    "Dit is heel lastig te berekenen en zorgt voor een heel hoge complexiteit.\n",
    "Hier komt echter de veronderstelling van onafhankelijkheid van de woorden in de tekst goed van pas om deze vergelijking te vereenvoudigen.\n",
    "We bekomen namelijk:\n",
    "\n",
    "$P(\\text{Spam}|w_1,w_2, \\dots w_n) = \\frac{P(w_1|\\text{Spam})P(w_2|\\text{Spam})\\dots P(w_n|\\text{Spam})P(\\text{Spam})}{P(w_1,w_2, \\dots w_n)} = \\frac{P(\\text{Spam})\\prod \\limits_{i=1}^{n}P(w_i|\\text{Spam})}{P(w_1,w_2, \\dots w_n)}$\n",
    "\n",
    "De noemer hierin zorgt ervoor dat de teller terug omgezet wordt naar een kans (met een waarde tussen 0 en 1).\n",
    "Deze is echter onafhankelijk van de kans of het spam is of niet.\n",
    "We hebben ook niet de exacte kans nodig maar moeten gewoon weten of de teller het grootst is als het spam is of niet.\n",
    "Daarom kan de noemer dus weggelaten worden met als volgende resultaat.\n",
    "\n",
    "$P(\\text{Spam}|w_1,w_2, \\dots w_n) \\propto P(\\text{Spam})\\prod \\limits_{i=1}^{n}P(w_i|\\text{Spam})$\n",
    "\n",
    "Stel dat we de volgende gegevens hebben over een dataset met 300 spam mails en 850 ham mails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae6f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd34dc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Woord</th>\n",
       "      <th>Spam frequentie</th>\n",
       "      <th>Spam kans</th>\n",
       "      <th>Ham frequentie</th>\n",
       "      <th>Ham kans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customer</td>\n",
       "      <td>100</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>200</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advise</td>\n",
       "      <td>50</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>70</td>\n",
       "      <td>0.082353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>120</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.035294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>money</td>\n",
       "      <td>60</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>450</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number</td>\n",
       "      <td>180</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>660</td>\n",
       "      <td>0.776471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Woord  Spam frequentie  Spam kans  Ham frequentie  Ham kans\n",
       "0  customer              100   0.333333             200  0.235294\n",
       "1    advise               50   0.166667              70  0.082353\n",
       "2    Africa              120   0.400000              30  0.035294\n",
       "3     money               60   0.200000             450  0.529412\n",
       "4    number              180   0.600000             660  0.776471"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aantal_spam_mails = 300\n",
    "aantal_ham_mails = 850\n",
    "\n",
    "woord = [\"customer\", \"advise\", \"Africa\", \"money\", \"number\"]\n",
    "spam_freq = [100,50, 120,60, 180]\n",
    "spam_prob = [x/aantal_spam_mails for x in spam_freq]\n",
    "ham_freq = [200, 70, 30, 450, 660]\n",
    "ham_prob =  [x/aantal_ham_mails for x in ham_freq]\n",
    "\n",
    "df = pd.DataFrame({\"Woord\": woord, \"Spam frequentie\": spam_freq, \"Spam kans\": spam_prob, \"Ham frequentie\": ham_freq, \"Ham kans\": ham_prob})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6860e81a",
   "metadata": {},
   "source": [
    "Beantwoord nu de volgende vragen:\n",
    "* Wat is $P(\\text{Spam})$, de kans dat een willekeurige mail spam is in de dataset?\n",
    "* Doe een manuele classificatie van de zin \"Africa advise money\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9039a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30434782608695654 0.6956521739130435\n",
      "Africa advise money is spam\n"
     ]
    }
   ],
   "source": [
    "pSpam = 350/(850+300)\n",
    "pHam = 1-pSpam\n",
    "print(pSpam, pHam)\n",
    "\n",
    "pTextIsSpam = pSpam * 0.4 * 0.17 * 0.2\n",
    "pTextIsHam = pHam * 0.035 * 0.08 * 0.53\n",
    "\n",
    "if(pTextIsSpam > pTextIsHam):\n",
    "    print(\"Africa advise money is spam\")\n",
    "else:\n",
    "    print(\"Africa advise money is ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec642a",
   "metadata": {},
   "source": [
    "**Hoe wordt er omgegaan met classificatie van woorden die niet in de dataset zaten?**\n",
    "\n",
    "Indien een mail uit de testset een woord bevat die nooit gezien was in de trainingsset, dan kan deze mail niet geclassificeerd worden omdat de kans van het woord steeds 0 is.\n",
    "Er zijn twee mogelijkheden om hiermee om te gaan. \n",
    "* Ofwel laat je die eruit vallen maar dan verlies je informatie.\n",
    "* Ofwel geef je deze woorden toch een bepaalde kans.\n",
    "\n",
    "Dit laatste kan gebeuren door middel van Laplacian Smoothing.\n",
    "De formule hiervoor is: \n",
    "\n",
    "$P(w) = \\frac{C(w) + \\alpha}{N+\\alpha V}$\n",
    "\n",
    "met \n",
    "* P(w) de uiteindelijke kans van het woord\n",
    "* C(w) het aantal mails waarin het woord voorkomt\n",
    "* N het aantal spam-mails\n",
    "* V het aantal verschillende woorden (features) in de dataset\n",
    "* $\\alpha$ een hyperparameter dat aangeeft hoeveel gewicht de ongeziene woorden moeten krijgen.\n",
    "    * Kleine waarde $\\rightarrow$ klein belang van ongeziene woorden $\\rightarrow$ neiging tot overfitting\n",
    "    * Grote waarde $\\rightarrow$ groot belang van ongeziene woorden $\\rightarrow$ neiging tot underfitting \n",
    "    \n",
    "Het algemene concept van Laplacian smoothing is om voor ongeziene woorden een extra fictieve mail toe te voegen die enkel bestaat uit dit woord.\n",
    "De $\\alpha$ is dan hoeveel keer deze mail wordt toegevoegd.\n",
    "Bereken voor een $\\alpha=2$ opnieuw de kansen in het dataframe df.\n",
    "Voeg hier ook een lijn aan toe voor woorden die niet in de dataset aanwezig zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ee34fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Woord</th>\n",
       "      <th>Spam frequentie</th>\n",
       "      <th>Spam kans</th>\n",
       "      <th>Ham frequentie</th>\n",
       "      <th>Ham kans</th>\n",
       "      <th>KansSpamSmoothed</th>\n",
       "      <th>KansHamSmoothed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customer</td>\n",
       "      <td>100</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>200</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.329032</td>\n",
       "      <td>0.234884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advise</td>\n",
       "      <td>50</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>70</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.167742</td>\n",
       "      <td>0.083721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>120</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.393548</td>\n",
       "      <td>0.037209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>money</td>\n",
       "      <td>60</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>450</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.525581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number</td>\n",
       "      <td>180</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>660</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.769767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Woord  Spam frequentie  Spam kans  Ham frequentie  Ham kans  \\\n",
       "0  customer              100   0.333333             200  0.235294   \n",
       "1    advise               50   0.166667              70  0.082353   \n",
       "2    Africa              120   0.400000              30  0.035294   \n",
       "3     money               60   0.200000             450  0.529412   \n",
       "4    number              180   0.600000             660  0.776471   \n",
       "\n",
       "   KansSpamSmoothed  KansHamSmoothed  \n",
       "0          0.329032         0.234884  \n",
       "1          0.167742         0.083721  \n",
       "2          0.393548         0.037209  \n",
       "3          0.200000         0.525581  \n",
       "4          0.587097         0.769767  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bereken de geupdate matrix met de kansen\n",
    "\n",
    "alpha=2\n",
    "N_spam = 300\n",
    "N_ham = 850\n",
    "V =len(df)\n",
    "\n",
    "df['KansSpamSmoothed'] = (df['Spam frequentie'] + alpha) / (N_spam + alpha * V)\n",
    "df['KansHamSmoothed'] = (df['Ham frequentie'] + alpha) / (N_ham + alpha * V)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e85a6",
   "metadata": {},
   "source": [
    "Voer nu opnieuw manuele classificatie uit voor de zin \"Europe advise money\" door gebruik te maken van Laplacian Smoothing.\n",
    "Is deze zin Spam of Ham?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018ca9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe advise money is ham\n"
     ]
    }
   ],
   "source": [
    "pTextIsSpam = pSpam * 2/(N_spam + 2* V) * 0.167742 * 0.2\n",
    "pTextIsHam = pHam * 2/(N_ham + 2* V) * 0.083721 * 0.525581\n",
    "\n",
    "if(pTextIsSpam > pTextIsHam):\n",
    "    print(\"Europe advise money is spam\")\n",
    "else:\n",
    "    print(\"Europe advise money is ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154453b3",
   "metadata": {},
   "source": [
    "**Probleem van veel kansen te vermenigvuldigen**\n",
    "\n",
    "Naast het probleem van ongeziene woorden, kan er nog een probleem optreden bij het werken met de kansberekeningen.\n",
    "Aangezien kansen een waarde tussen 0 en 1 zijn kan het zijn dat er bij vermenigvuldiging van veel kansen een floating-point underflow optreed omdat het resultaat steeds kleiner en kleiner gaat worden.\n",
    "Om dit tegen te gaan kan men gebruik maken van het logaritme van de kansen.\n",
    "Dit wordt ook **log likelihood** genoemd en wordt berekend als volgt:\n",
    "\n",
    "$log(P(\\text{Spam}|w_1,w_2, \\dots w_n)) \\propto log(P(\\text{Spam})) + \\sum\\limits_{i=1}^{n}log(P(w_i|\\text{Spam}))$\n",
    "\n",
    "De resulterende klasse is nog steeds de klasse met de hoogste log-likelihood.\n",
    "\n",
    "Bereken de log-likelihood voor de zin \"Europe advice money\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ae4fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "pTextIsSpam = math.log(pSpam) + math.log(2/(N_spam + 2* V)) +  math.log(0.167742) + math.log(0.2)\n",
    "pTextIsHam = math.log(pHam) + math.log(2/(N_ham + 2* V)) + math.log(0.083721) + math.log(0.525581)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd2291",
   "metadata": {},
   "source": [
    "**Probleem van gelijkaardige woorden (Moet nog niet gekend zijn voor de type A evaluatie, komt later terug)**\n",
    "\n",
    "Daarnaast is het duidelijk dat elke vorm van geschreven tekst een groot aantal overbodige woorden betekenen. \n",
    "Dit zijn dan bijvoorbeeld woorden die in heel veel zinnen voorkomen zoals ik, hij, en, daar, ...\n",
    "Deze woorden gaan geen informatie geven om de classificatie uit te voeren en kunnen dus ook genegeerd worden.\n",
    "Daarnaast kan men ook de vraag stellen over vervoegingen van werkwoorden of meervouden een apart woord moeten zijn.\n",
    "\n",
    "Over het algemeen gezien kunnen we de volgende stappen uitvoeren om de tekst bruikbaarder te maken:\n",
    "* Html/xml/... tags verwijderen indien er zijn ([BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/))\n",
    "* Cijfers/speciale symbolen verwijderen\n",
    "* Alles omzetten naar lowercase\n",
    "* Stopwoorden verwijderen ([nltk.corpus](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/)) (vergeet niet de stopwords te downloaden indien nodig)\n",
    "* Alle woorden herleiden naar hun stam ([nltk SnowballStemmer](https://www.nltk.org/_modules/nltk/stem/snowball.html))\n",
    "* Verwijder te korte woorden\n",
    "\n",
    "Deze stappen kunnen door middel van de volgende lijnen code uitgevoerd worden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc18f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
