{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42d5431",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "In de reeds besproken machine learning technieken hebben we reeds een aantal keer vermeld dat er hyperparameters (denk aan regularisatieparameters, manieren van regularisatie, kernel type, ...).\n",
    "\n",
    "In het geval van lineaire regressie gaat het dan over:\n",
    "* L1 of L2 norm\n",
    "* Regularisatieparameter $\\lambda$\n",
    "* learning rate\n",
    "\n",
    "In het geval van SVM over:\n",
    "* Type kernel\n",
    "* Regularisatieparameter C\n",
    "* Regularisatieparameter $\\gamma$\n",
    "\n",
    "Tot nu bestond de zoektocht naar de optimale combinatie van deze parameters door het manueel uitproberen en evalueren van een reeks combinaties van parameters.\n",
    "Deze methode is echter niet schaalbaar en kan geautomatiseerd worden.\n",
    "Dit gebeurd door middel van een gridsearch.\n",
    "\n",
    "## Gridsearch\n",
    "\n",
    "Het gridsearch algoritme bestaat eruit om een lijst op te stellen voor elke parameter welke waarden moeten getest worden.\n",
    "Voor elke mogelijke combinatie van parameters gaat er dan een model getrained en geevalueerd worden.\n",
    "Een voorbeeld van hoe dit kan geautomatiseerd worden binnen sklearn kan [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) gevonden worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3488e5",
   "metadata": {},
   "source": [
    "De standaard methode van hierboven gaat alle combinaties afgaan.\n",
    "Andere methoden die sneller maar niet alle combinaties aftoetsen zijn\n",
    "* [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)\n",
    "*[HalvingGridSearchCv](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV)\n",
    "*[HalvingRandomizedSearchCv](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV)\n",
    "\n",
    "Belangrijk om hierbij op te merken is dat het GridSearch algoritme enkel verschillende parameters van het model trained en dat er geen eigenschappen van de data kan veranderd worden.\n",
    "Indien je ook een exhausieve search wilt doen van het aantal hogere orde features of de vorm van scaling die gebruikt wordt op input parameters. Moet je een eigen wrapper schrijven die nog deze zaken uittest en de performantie van de uiteindelijke modellen vergelijkt.\n",
    "\n",
    "## Validatieset\n",
    "\n",
    "Welke data kunnen we nu gebruiken om deze gridsearch te evalueren.\n",
    "Zowel de testdata als de trainingsdata kan niet gebruikt worden omdat we niet kunnen evalueren op de data waarmee het model getrained is.\n",
    "Om deze reden wordt de dataset typisch in drie opgedeeld, namelijk een training-, test- en validatieset.\n",
    "De validatieset is de data die dan gebruikt kan worden voor hyperparameter tuning.\n",
    "Typisch wordt de dataset dan in de volgende groottes opgedeeld:\n",
    "* Testset: 15%\n",
    "* Validatieset: 15% \n",
    "* Trainingsdata: 70%\n",
    "\n",
    "Dit zijn echter geen vaste waarden en kunnen wat verschillen in de praktijk.\n",
    "Hoe meer data je beschibaar is hoe groter het percentage trainingsdata kan zijn. \n",
    "In het geval van big-data applicaties kan dit oplopen tot 98%.\n",
    "\n",
    "## K-fold cross validation\n",
    "\n",
    "Bij het steeds gebruiken van dezelfde validatieset is het mogelijk dat er een unieke split is die leidt tot een onverwacht goed of slecht resultaat.\n",
    "Om dit tegen te gaan kan er gebruik gemaakt worden van K-fold cross validation.\n",
    "Daarbij berekenen we de verwachte error K keer, elke keer met een andere train en validatie set om zo de kans te verhogen dat het uiteindelijke model ook goed werkt op de testset met ongeziene data.\n",
    "Standaard wordt er bij het gebruik van het gridsearch algoritme gebruik gemaakt van 5 folds voor het zoeken naar de beste hyperparameters.\n",
    "Indien de standaard manier niet voldoet voor de gewenste toepassing kan je ook de split rechtstreeks uitvoeren.\n",
    "Meer informatie over deze methode vind je [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfb555",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "In [deze dataset](https://www.kaggle.com/mathchi/diabetes-data-set) is een hele reeks data beschikbaar over een aantal medische eigenschappen van personen en of deze personen diabetes hebben of niet.\n",
    "Ga nu op zoek naar het beste model om te voorspellen of een persoon diabetes gaat hebben of niet.\n",
    "Test hierbij zowel de logistische regressie en svm methoden en maak gebruik van gridsearch met 10-fold cross validation om de verschillende hyperparameters te testen. \n",
    "\n",
    "Wat is de hoogst behaalde accuraatheid en de benodigde hyperparameters?\n",
    "\n",
    "Indien dit gelukt is, zoek ook het model dat de hoogste weighted f1-score behaald. \n",
    "Welke techniek gebruikte dit model en welke hyperparameters zijn er hiervoor gekozen?\n",
    "Vergelijk beide modellen. Is er een significant verschil in de resulterende hyperparameters?\n",
    "Is de behaalde accuraatheid sterk afwijkend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#od.download(\"https://www.kaggle.com/mathchi/diabetes-data-set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31b9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./diabetes-data-set/diabetes.csv\")\n",
    "display(df.head())\n",
    "y = df.Outcome\n",
    "X = df.drop(\"Outcome\", axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09239695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
